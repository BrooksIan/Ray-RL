{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c3b11c-e80d-4c81-b030-377a857c688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.9/site-packages (2.3.1)\n",
      "Collecting tensorflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"ray[rllib]\" tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82b64bc-3725-4487-a471-2fb0054953a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[K     |████████████████████████████████| 953 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.9/site-packages (from gymnasium) (4.5.0)\n",
      "Collecting numpy>=1.21.0\n",
      "  Using cached numpy-1.26.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Collecting farama-notifications>=0.0.1\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /runtime-addons/cmladdon-2.0.41-b225/opt/cmladdons/python/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.8.0)\n",
      "Installing collected packages: numpy, farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 numpy-1.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium\n",
    "%pip install dm-tree\n",
    "%pip install wheel\n",
    "%pip install pandas\n",
    "%pip install opencv-python\n",
    "%pip install scikit-image\n",
    "%pip install lz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe08441a-a18d-4903-b145-9adca49404ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[K     |████████████████▏               | 313.8 MB 136.2 MB/s eta 0:00:03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 619.9 MB 15 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 168.4 MB 94 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 177.1 MB 102 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 1.3 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1) (3.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from torch==2.0.1) (3.10.7)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch==2.0.1) (3.2.1)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 102.6 MB 6.5 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 63.3 MB 111.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 54.6 MB 107.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 114.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 114.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |█████████████████               | 295.3 MB 138.8 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 557.1 MB 11 kB/s /s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch==2.0.1) (4.5.0)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 173.2 MB 35 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████    | 276.4 MB 132.0 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 317.1 MB 39 kB/s \n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 95.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (58.1.0)\n",
      "Collecting lit\n",
      "  Downloading lit-17.0.4.tar.gz (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 109.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 113.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch==2.0.1) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 108.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=9727c4e11aab92e917b611874a564bb9f20c47fa91499bd845f4ac7734913d96\n",
      "  Stored in directory: /home/cdsw/.cache/pip/wheels/65/b5/5f/393c25945f561fcc619d4ce4ca365020675dbddb0c92cb5ef6\n",
      "Successfully built lit\n",
      "Installing collected packages: nvidia-cublas-cu11, mpmath, lit, cmake, triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, torch\n",
      "Successfully installed cmake-3.27.7 lit-17.0.4 mpmath-1.3.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30f3ef7-b09b-4490-b924-f4bf447cac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:17:49,327\tWARNING algorithm_config.py:723 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "Could not instantiate TBXLogger: No module named 'tensorboardX'.\n",
      "2023-11-08 15:17:51,837\tWARNING services.py:1780 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.97gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-11-08 15:17:51,981\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=1678)\u001b[0m 2023-11-08 15:18:00,920\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "2023-11-08 15:18:01,165\tWARNING algorithm_config.py:723 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Algorithm.train()`. Instead, you will have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "2023-11-08 15:18:06,967\tINFO trainable.py:172 -- Trainable.setup took 17.412 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-11-08 15:18:06,968\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2027)\u001b[0m 2023-11-08 15:18:06,949\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.09323933583594138, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.971728039813298, 'policy_loss': 0.009938490283625421, 'vf_loss': 9.961769769525015, 'vf_explained_var': -2.813922461643014e-05, 'kl': 9.902443609477786e-05, 'entropy': 1.7916600155574018, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'sampler_results': {'episode_reward_max': -342.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -777.25, 'episode_len_mean': 195.55, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3397442709500048, 'mean_inference_ms': 1.0516168116808298, 'mean_action_processing_ms': 0.1410536620689594, 'mean_env_wait_ms': 0.0827159362099041, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026715993881225586, 'StateBufferConnector_ms': 0.005537271499633789, 'ViewRequirementAgentConnector_ms': 0.12455463409423828}}, 'episode_reward_max': -342.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -777.25, 'episode_len_mean': 195.55, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3397442709500048, 'mean_inference_ms': 1.0516168116808298, 'mean_action_processing_ms': 0.1410536620689594, 'mean_env_wait_ms': 0.0827159362099041, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026715993881225586, 'StateBufferConnector_ms': 0.005537271499633789, 'ViewRequirementAgentConnector_ms': 0.12455463409423828}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'timesteps_total': 4000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 4000, 'timers': {'training_iteration_time_ms': 8777.258, 'load_time_ms': 0.711, 'load_throughput': 5624276.232, 'learn_time_ms': 5460.001, 'learn_throughput': 732.601, 'synch_weights_time_ms': 2.285}, 'counters': {'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'done': False, 'episodes_total': 20, 'training_iteration': 1, 'trial_id': 'default', 'experiment_id': '73caeeee2c6b43dd93bc060d090a85e0', 'date': '2023-11-08_15-18-15', 'timestamp': 1699456695, 'time_this_iter_s': 8.781661987304688, 'time_total_s': 8.781661987304688, 'pid': 219, 'hostname': '5eu4qh56vkhhzwbj', 'node_ip': '100.100.181.140', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_trainer_workers': 0, 'num_gpus_per_trainer_worker': 0, 'num_cpus_per_trainer_worker': 1, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'rl_trainer_class': None, '_enable_rl_trainer_api': False, '_rl_trainer_hps': RLTrainerHPs(), 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7f04fc7f0f10>}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'rl_module_class': None, '_enable_rl_module_api': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f060bc8e550>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 8.781661987304688, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 17.414536476135254, 'perf': {'cpu_util_percent': 34.215384615384615, 'ram_util_percent': 7.761538461538461}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.12134090537025083, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.963708470457343, 'policy_loss': 0.0047252198651192645, 'vf_loss': 9.95889279868013, 'vf_explained_var': -5.7692809771466e-06, 'kl': 0.0009044770671626479, 'entropy': 1.7900299583711932, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 1395.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'sampler_results': {'episode_reward_max': -342.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -781.125, 'episode_len_mean': 197.775, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33945380045113804, 'mean_inference_ms': 1.051982910249934, 'mean_action_processing_ms': 0.14118264771023173, 'mean_env_wait_ms': 0.08264368172789213, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026484131813049316, 'StateBufferConnector_ms': 0.005379319190979004, 'ViewRequirementAgentConnector_ms': 0.12360095977783203}}, 'episode_reward_max': -342.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -781.125, 'episode_len_mean': 197.775, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33945380045113804, 'mean_inference_ms': 1.051982910249934, 'mean_action_processing_ms': 0.14118264771023173, 'mean_env_wait_ms': 0.08264368172789213, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026484131813049316, 'StateBufferConnector_ms': 0.005379319190979004, 'ViewRequirementAgentConnector_ms': 0.12360095977783203}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'timesteps_total': 8000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 8000, 'timers': {'training_iteration_time_ms': 8897.614, 'load_time_ms': 1.361, 'load_throughput': 2939503.46, 'learn_time_ms': 5579.21, 'learn_throughput': 716.947, 'synch_weights_time_ms': 2.142}, 'counters': {'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'done': False, 'episodes_total': 40, 'training_iteration': 2, 'trial_id': 'default', 'experiment_id': '73caeeee2c6b43dd93bc060d090a85e0', 'date': '2023-11-08_15-18-24', 'timestamp': 1699456704, 'time_this_iter_s': 9.021654844284058, 'time_total_s': 17.803316831588745, 'pid': 219, 'hostname': '5eu4qh56vkhhzwbj', 'node_ip': '100.100.181.140', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_trainer_workers': 0, 'num_gpus_per_trainer_worker': 0, 'num_cpus_per_trainer_worker': 1, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'rl_trainer_class': None, '_enable_rl_trainer_api': False, '_rl_trainer_hps': RLTrainerHPs(), 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7f04e448ef70>}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'rl_module_class': None, '_enable_rl_module_api': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f060bc8e550>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 17.803316831588745, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'warmup_time': 17.414536476135254, 'perf': {'cpu_util_percent': 37.07692307692308, 'ram_util_percent': 7.861538461538464}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.1787262631279807, 'cur_kl_coeff': 0.05000000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938155731078117, 'policy_loss': -0.0025699268355565043, 'vf_loss': 9.940538068996963, 'vf_explained_var': -0.000143604701565158, 'kl': 0.0037520915941898045, 'entropy': 1.7792791235831475, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 2325.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'sampler_results': {'episode_reward_max': -342.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -765.95, 'episode_len_mean': 198.45, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0, -776.0, -767.0, -740.0, -614.0, -722.0, -677.0, -722.0, -731.0, -677.0, -695.0, -857.0, -857.0, -686.0, -767.0, -695.0, -722.0, -785.0, -785.0, -697.0, -740.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.339381109857496, 'mean_inference_ms': 1.052637192564674, 'mean_action_processing_ms': 0.14130180631681427, 'mean_env_wait_ms': 0.0826895367892219, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.02636432647705078, 'StateBufferConnector_ms': 0.00533302625020345, 'ViewRequirementAgentConnector_ms': 0.12356917063395183}}, 'episode_reward_max': -342.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -765.95, 'episode_len_mean': 198.45, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0, -776.0, -767.0, -740.0, -614.0, -722.0, -677.0, -722.0, -731.0, -677.0, -695.0, -857.0, -857.0, -686.0, -767.0, -695.0, -722.0, -785.0, -785.0, -697.0, -740.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.339381109857496, 'mean_inference_ms': 1.052637192564674, 'mean_action_processing_ms': 0.14130180631681427, 'mean_env_wait_ms': 0.0826895367892219, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.02636432647705078, 'StateBufferConnector_ms': 0.00533302625020345, 'ViewRequirementAgentConnector_ms': 0.12356917063395183}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'timesteps_total': 12000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 12000, 'timers': {'training_iteration_time_ms': 9073.462, 'load_time_ms': 1.64, 'load_throughput': 2438666.99, 'learn_time_ms': 5748.179, 'learn_throughput': 695.873, 'synch_weights_time_ms': 2.147}, 'counters': {'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'done': False, 'episodes_total': 60, 'training_iteration': 3, 'trial_id': 'default', 'experiment_id': '73caeeee2c6b43dd93bc060d090a85e0', 'date': '2023-11-08_15-18-34', 'timestamp': 1699456714, 'time_this_iter_s': 9.42923355102539, 'time_total_s': 27.232550382614136, 'pid': 219, 'hostname': '5eu4qh56vkhhzwbj', 'node_ip': '100.100.181.140', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_trainer_workers': 0, 'num_gpus_per_trainer_worker': 0, 'num_cpus_per_trainer_worker': 1, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'rl_trainer_class': None, '_enable_rl_trainer_api': False, '_rl_trainer_hps': RLTrainerHPs(), 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7f04e4197370>}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'rl_module_class': None, '_enable_rl_module_api': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f060bc8e550>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 27.232550382614136, 'timesteps_since_restore': 0, 'iterations_since_restore': 3, 'warmup_time': 17.414536476135254, 'perf': {'cpu_util_percent': 37.199999999999996, 'ram_util_percent': 7.900000000000002}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.2574518475881828, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.897883761826382, 'policy_loss': -0.00829357922437691, 'vf_loss': 9.906003770520611, 'vf_explained_var': 0.0002308087323301582, 'kl': 0.006943275327075361, 'entropy': 1.7465702591403838, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 3255.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'sampler_results': {'episode_reward_max': -258.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -735.6625, 'episode_len_mean': 197.575, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0, -776.0, -767.0, -740.0, -614.0, -722.0, -677.0, -722.0, -731.0, -677.0, -695.0, -857.0, -857.0, -686.0, -767.0, -695.0, -722.0, -785.0, -785.0, -697.0, -740.0, -641.0, -560.0, -587.0, -731.0, -632.0, -258.0, -677.0, -641.0, -641.0, -758.0, -695.0, -713.0, -650.0, -632.0, -722.0, -695.0, -650.0, -677.0, -623.0, -713.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 99, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33939414793330736, 'mean_inference_ms': 1.053191754306535, 'mean_action_processing_ms': 0.14135912381294885, 'mean_env_wait_ms': 0.0827280606816542, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026410818099975586, 'StateBufferConnector_ms': 0.005310475826263428, 'ViewRequirementAgentConnector_ms': 0.12396186590194702}}, 'episode_reward_max': -258.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -735.6625, 'episode_len_mean': 197.575, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-785.0, -821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0, -776.0, -767.0, -740.0, -614.0, -722.0, -677.0, -722.0, -731.0, -677.0, -695.0, -857.0, -857.0, -686.0, -767.0, -695.0, -722.0, -785.0, -785.0, -697.0, -740.0, -641.0, -560.0, -587.0, -731.0, -632.0, -258.0, -677.0, -641.0, -641.0, -758.0, -695.0, -713.0, -650.0, -632.0, -722.0, -695.0, -650.0, -677.0, -623.0, -713.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 99, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33939414793330736, 'mean_inference_ms': 1.053191754306535, 'mean_action_processing_ms': 0.14135912381294885, 'mean_env_wait_ms': 0.0827280606816542, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026410818099975586, 'StateBufferConnector_ms': 0.005310475826263428, 'ViewRequirementAgentConnector_ms': 0.12396186590194702}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'timesteps_total': 16000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 16000, 'timers': {'training_iteration_time_ms': 9209.204, 'load_time_ms': 1.854, 'load_throughput': 2157633.154, 'learn_time_ms': 5883.075, 'learn_throughput': 679.917, 'synch_weights_time_ms': 2.172}, 'counters': {'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'done': False, 'episodes_total': 80, 'training_iteration': 4, 'trial_id': 'default', 'experiment_id': '73caeeee2c6b43dd93bc060d090a85e0', 'date': '2023-11-08_15-18-43', 'timestamp': 1699456723, 'time_this_iter_s': 9.620823860168457, 'time_total_s': 36.85337424278259, 'pid': 219, 'hostname': '5eu4qh56vkhhzwbj', 'node_ip': '100.100.181.140', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_trainer_workers': 0, 'num_gpus_per_trainer_worker': 0, 'num_cpus_per_trainer_worker': 1, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'rl_trainer_class': None, '_enable_rl_trainer_api': False, '_rl_trainer_hps': RLTrainerHPs(), 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7f04fc7e1be0>}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'rl_module_class': None, '_enable_rl_module_api': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f060bc8e550>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 36.85337424278259, 'timesteps_since_restore': 0, 'iterations_since_restore': 4, 'warmup_time': 17.414536476135254, 'perf': {'cpu_util_percent': 37.47857142857142, 'ram_util_percent': 7.900000000000003}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.3492329149637171, 'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.886191442961334, 'policy_loss': -0.00935700362177706, 'vf_loss': 9.89532252486034, 'vf_explained_var': -4.2222456265521306e-05, 'kl': 0.00903524985112694, 'entropy': 1.7067528732361332, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 4185.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': -112.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -700.29, 'episode_len_mean': 196.62, 'episode_media': {}, 'episodes_this_iter': 21, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0, -776.0, -767.0, -740.0, -614.0, -722.0, -677.0, -722.0, -731.0, -677.0, -695.0, -857.0, -857.0, -686.0, -767.0, -695.0, -722.0, -785.0, -785.0, -697.0, -740.0, -641.0, -560.0, -587.0, -731.0, -632.0, -258.0, -677.0, -641.0, -641.0, -758.0, -695.0, -713.0, -650.0, -632.0, -722.0, -695.0, -650.0, -677.0, -623.0, -713.0, -569.0, -704.0, -497.0, -560.0, -587.0, -471.0, -713.0, -641.0, -533.0, -614.0, -614.0, -112.0, -569.0, -677.0, -569.0, -578.0, -497.0, -578.0, -641.0, -659.0, -578.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 99, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 186, 200, 200, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3393591408752216, 'mean_inference_ms': 1.0539223513581584, 'mean_action_processing_ms': 0.14141641540180525, 'mean_env_wait_ms': 0.08276015079989948, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026280641555786133, 'StateBufferConnector_ms': 0.00529789924621582, 'ViewRequirementAgentConnector_ms': 0.1236729621887207}}, 'episode_reward_max': -112.0, 'episode_reward_min': -884.0, 'episode_reward_mean': -700.29, 'episode_len_mean': 196.62, 'episodes_this_iter': 21, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-821.0, -659.0, -866.0, -812.0, -722.0, -749.0, -839.0, -830.0, -821.0, -839.0, -857.0, -342.0, -812.0, -794.0, -749.0, -884.0, -821.0, -821.0, -722.0, -803.0, -722.0, -776.0, -677.0, -821.0, -839.0, -821.0, -758.0, -785.0, -749.0, -884.0, -794.0, -731.0, -794.0, -812.0, -704.0, -830.0, -749.0, -821.0, -830.0, -776.0, -767.0, -740.0, -614.0, -722.0, -677.0, -722.0, -731.0, -677.0, -695.0, -857.0, -857.0, -686.0, -767.0, -695.0, -722.0, -785.0, -785.0, -697.0, -740.0, -641.0, -560.0, -587.0, -731.0, -632.0, -258.0, -677.0, -641.0, -641.0, -758.0, -695.0, -713.0, -650.0, -632.0, -722.0, -695.0, -650.0, -677.0, -623.0, -713.0, -569.0, -704.0, -497.0, -560.0, -587.0, -471.0, -713.0, -641.0, -533.0, -614.0, -614.0, -112.0, -569.0, -677.0, -569.0, -578.0, -497.0, -578.0, -641.0, -659.0, -578.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 111, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 196, 200, 200, 200, 200, 200, 200, 99, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 186, 200, 200, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3393591408752216, 'mean_inference_ms': 1.0539223513581584, 'mean_action_processing_ms': 0.14141641540180525, 'mean_env_wait_ms': 0.08276015079989948, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.026280641555786133, 'StateBufferConnector_ms': 0.00529789924621582, 'ViewRequirementAgentConnector_ms': 0.1236729621887207}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'timesteps_total': 20000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 9244.422, 'load_time_ms': 1.98, 'load_throughput': 2020280.333, 'learn_time_ms': 5917.205, 'learn_throughput': 675.995, 'synch_weights_time_ms': 2.176}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': False, 'episodes_total': 101, 'training_iteration': 5, 'trial_id': 'default', 'experiment_id': '73caeeee2c6b43dd93bc060d090a85e0', 'date': '2023-11-08_15-18-53', 'timestamp': 1699456733, 'time_this_iter_s': 9.389519691467285, 'time_total_s': 46.24289393424988, 'pid': 219, 'hostname': '5eu4qh56vkhhzwbj', 'node_ip': '100.100.181.140', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_trainer_workers': 0, 'num_gpus_per_trainer_worker': 0, 'num_cpus_per_trainer_worker': 1, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'Taxi-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'is_atari': False, 'auto_wrap_old_gym_envs': True, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': True, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'rl_trainer_class': None, '_enable_rl_trainer_api': False, '_rl_trainer_hps': RLTrainerHPs(), 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec object at 0x7f04e4094730>}, 'policy_states_are_swappable': False, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 1, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, 'rl_module_class': None, '_enable_rl_module_api': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'horizon': -1, 'soft_horizon': -1, 'no_done_at_end': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': (None, None, None, None)}, 'policy_mapping_fn': <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f060bc8e550>, 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': -1, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 2}, 'time_since_restore': 46.24289393424988, 'timesteps_since_restore': 0, 'iterations_since_restore': 5, 'warmup_time': 17.414536476135254, 'perf': {'cpu_util_percent': 37.16923076923077, 'ram_util_percent': 7.900000000000002}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': -95.0,\n",
       "  'episode_reward_min': -668.0,\n",
       "  'episode_reward_mean': -458.6,\n",
       "  'episode_len_mean': 186.2,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 10,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-497.0,\n",
       "    -95.0,\n",
       "    -524.0,\n",
       "    -668.0,\n",
       "    -452.0,\n",
       "    -497.0,\n",
       "    -506.0,\n",
       "    -452.0,\n",
       "    -443.0,\n",
       "    -452.0],\n",
       "   'episode_lengths': [200, 62, 200, 200, 200, 200, 200, 200, 200, 200]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.3114747412410783,\n",
       "   'mean_inference_ms': 1.0532826041253869,\n",
       "   'mean_action_processing_ms': 0.13816081511353653,\n",
       "   'mean_env_wait_ms': 0.08120897695446169,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': 0.02523183822631836,\n",
       "   'StateBufferConnector_ms': 0.005538463592529297,\n",
       "   'ViewRequirementAgentConnector_ms': 0.1195669174194336},\n",
       "  'num_agent_steps_sampled_this_iter': 1862,\n",
       "  'num_env_steps_sampled_this_iter': 1862,\n",
       "  'timesteps_this_iter': 1862}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "config = (  # 1. Configure the algorithm,\n",
    "    PPOConfig()\n",
    "    .environment(\"Taxi-v3\")\n",
    "    .rollouts(num_rollout_workers=2)\n",
    "    .training(model={\"fcnet_hiddens\": [64, 64]})\n",
    "    .framework(\"torch\")\n",
    "    .evaluation(evaluation_num_workers=1)\n",
    ")\n",
    "\n",
    "algo = config.build()  # 2. build the algorithm,\n",
    "\n",
    "for _ in range(5):\n",
    "    print(algo.train())  # 3. train it,\n",
    "\n",
    "algo.evaluate()  # 4. and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979e2ac-982c-4e35-a7bb-fd8ab56416bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
